{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YaI4ju4j34B",
        "outputId": "f8fd1904-b702-43e8-9193-ecc8d2b50632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Vocabulary Size: 3323\n",
            "X_train shape: (3371, 20)\n",
            "X_test shape: (843, 20)\n",
            "y_train shape: (3371,)\n",
            "y_test shape: (843,)\n",
            "Vocabulary size (unique items): 3323\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "file_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\\Online Retail.xlsx\"\n",
        "df = pd.read_excel(file_path, sheet_name='Online Retail')\n",
        "\n",
        "# Cleaning\n",
        "df_cleaned = df.dropna(subset=['CustomerID', 'Description'])\n",
        "df_cleaned = df_cleaned[df_cleaned['Quantity'] > 0]\n",
        "\n",
        "# Encoding\n",
        "df_sorted = df_cleaned.sort_values(by=['CustomerID', 'InvoiceDate'])\n",
        "item_encoder = LabelEncoder()\n",
        "df_sorted['ItemID'] = item_encoder.fit_transform(df_sorted['Description'])\n",
        "\n",
        "# Grouping by Customer\n",
        "sequential_data = df_sorted.groupby('CustomerID')['ItemID'].apply(list).reset_index(name='ItemSequence')\n",
        "\n",
        "# Lower minimum sequence length\n",
        "min_sequence_length = 3\n",
        "sequential_data = sequential_data[sequential_data['ItemSequence'].apply(len) >= min_sequence_length]\n",
        "\n",
        "# Pad and create sequences\n",
        "item_sequences = sequential_data['ItemSequence'].tolist()\n",
        "sequence_length = 20\n",
        "padded_sequences = pad_sequences(item_sequences, maxlen=sequence_length, padding='pre')\n",
        "\n",
        "def create_sequences(sequences, seq_length=20):\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(max(1, len(seq) - seq_length + 1)):\n",
        "            X.append(seq[i:i + seq_length])\n",
        "            y.append(seq[min(i + seq_length, len(seq) - 1)])  # Adjust for boundaries\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(padded_sequences, seq_length=sequence_length)\n",
        "\n",
        "# Dataset splitting\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Update unique_items to reflect the entire dataset\n",
        "unique_items = np.unique(np.concatenate([X_train.flatten(), X_test.flatten()]))\n",
        "\n",
        "# **Sanity Check: Clip Indices**\n",
        "X_train = np.clip(X_train, 0, len(unique_items) - 1)\n",
        "X_test = np.clip(X_test, 0, len(unique_items) - 1)\n",
        "y_train = np.clip(y_train, 0, len(unique_items) - 1)\n",
        "y_test = np.clip(y_test, 0, len(unique_items) - 1)\n",
        "\n",
        "print(f\"Updated Vocabulary Size: {len(unique_items)}\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "print(f\"Vocabulary size (unique items): {len(unique_items)}\")\n",
        "\n",
        "# Save preprocessed data\n",
        "np.save(\"X_train.npy\", X_train)\n",
        "np.save(\"X_test.npy\", X_test)\n",
        "np.save(\"y_train.npy\", y_train)\n",
        "np.save(\"y_test.npy\", y_test)\n",
        "np.save(\"unique_items.npy\", unique_items)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 100  # Increased embedding dimension\n",
        "hidden_units = 200  # More GRU units\n",
        "sequence_length = 20  # Increased sequence length\n",
        "batch_size = 32  # Adjust batch size\n",
        "epochs = 30  # Train for more epochs\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        step_start_time = time.time()\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, \"evaluation_results.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, 'evaluation_results.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YoHV-9dNkLht",
        "outputId": "794c8a0b-6a6e-4b2c-a82e-8646a18c1105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m387,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_9 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │         \u001b[38;5;34m181,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3877\u001b[0m)                │         \u001b[38;5;34m779,277\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">387,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">181,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3877</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">779,277</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,348,177\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,348,177</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,348,177\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,348,177</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1687 - loss: 8.0772\n",
            "105/105 ━━━━━━━━━━━━━ 32s total - accuracy: 0.1703 - loss: 8.1541\n",
            "\n",
            "Epoch 2/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0510 - loss: 7.4732\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.0515 - loss: 7.5444\n",
            "\n",
            "Epoch 3/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0485 - loss: 7.1065\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.0490 - loss: 7.1742\n",
            "\n",
            "Epoch 4/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0546 - loss: 6.8676\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.0552 - loss: 6.9330\n",
            "\n",
            "Epoch 5/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0587 - loss: 6.6950\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.0592 - loss: 6.7588\n",
            "\n",
            "Epoch 6/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0622 - loss: 6.5526\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.0628 - loss: 6.6150\n",
            "\n",
            "Epoch 7/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0660 - loss: 6.4223\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.0666 - loss: 6.4835\n",
            "\n",
            "Epoch 8/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0702 - loss: 6.2961\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.0708 - loss: 6.3560\n",
            "\n",
            "Epoch 9/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0745 - loss: 6.1699\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.0752 - loss: 6.2287\n",
            "\n",
            "Epoch 10/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0804 - loss: 6.0419\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.0811 - loss: 6.0995\n",
            "\n",
            "Epoch 11/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0889 - loss: 5.9105\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.0897 - loss: 5.9668\n",
            "\n",
            "Epoch 12/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1003 - loss: 5.7753\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.1013 - loss: 5.8303\n",
            "\n",
            "Epoch 13/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1145 - loss: 5.6367\n",
            "105/105 ━━━━━━━━━━━━━ 27s total - accuracy: 0.1156 - loss: 5.6904\n",
            "\n",
            "Epoch 14/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1309 - loss: 5.4957\n",
            "105/105 ━━━━━━━━━━━━━ 27s total - accuracy: 0.1321 - loss: 5.5480\n",
            "\n",
            "Epoch 15/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1492 - loss: 5.3534\n",
            "105/105 ━━━━━━━━━━━━━ 28s total - accuracy: 0.1507 - loss: 5.4044\n",
            "\n",
            "Epoch 16/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1694 - loss: 5.2109\n",
            "105/105 ━━━━━━━━━━━━━ 28s total - accuracy: 0.1710 - loss: 5.2606\n",
            "\n",
            "Epoch 17/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1907 - loss: 5.0691\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.1925 - loss: 5.1174\n",
            "\n",
            "Epoch 18/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2131 - loss: 4.9287\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.2151 - loss: 4.9756\n",
            "\n",
            "Epoch 19/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2364 - loss: 4.7908\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.2387 - loss: 4.8364\n",
            "\n",
            "Epoch 20/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2601 - loss: 4.6560\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.2625 - loss: 4.7004\n",
            "\n",
            "Epoch 21/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2838 - loss: 4.5242\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.2865 - loss: 4.5673\n",
            "\n",
            "Epoch 22/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3080 - loss: 4.3948\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.3110 - loss: 4.4366\n",
            "\n",
            "Epoch 23/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3324 - loss: 4.2680\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.3355 - loss: 4.3087\n",
            "\n",
            "Epoch 24/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3566 - loss: 4.1444\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.3599 - loss: 4.1838\n",
            "\n",
            "Epoch 25/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3802 - loss: 4.0240\n",
            "105/105 ━━━━━━━━━━━━━ 32s total - accuracy: 0.3838 - loss: 4.0623\n",
            "\n",
            "Epoch 26/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4030 - loss: 3.9072\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.4068 - loss: 3.9444\n",
            "\n",
            "Epoch 27/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4245 - loss: 3.7943\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.4286 - loss: 3.8304\n",
            "\n",
            "Epoch 28/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4449 - loss: 3.6854\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.4492 - loss: 3.7205\n",
            "\n",
            "Epoch 29/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4641 - loss: 3.5805\n",
            "105/105 ━━━━━━━━━━━━━ 34s total - accuracy: 0.4685 - loss: 3.6146\n",
            "\n",
            "Epoch 30/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4821 - loss: 3.4795\n",
            "105/105 ━━━━━━━━━━━━━ 35s total - accuracy: 0.4867 - loss: 3.5127\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0447, 0.4472, 0.4472, 0.0530)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Hyperparameters for Model 1 (Baseline)\n",
        "embedding_dim = 100  # Embedding dimension\n",
        "hidden_units = 200  # GRU units\n",
        "sequence_length = 20  # Sequence length\n",
        "batch_size = 32  # Batch size\n",
        "epochs = 30  # Number of epochs\n",
        "learning_rate = 0.0005  # Learning rate\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        step_start_time = time.time()\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, \"evaluation_results_model1.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, 'evaluation_results_model1.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xU44lIlPe3Fl",
        "outputId": "52a48eb1-5a2d-4ef6-e4d9-ac8d1dad3c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m387,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_10 (\u001b[38;5;33mGRU\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │         \u001b[38;5;34m181,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3877\u001b[0m)                │         \u001b[38;5;34m779,277\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">387,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">181,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3877</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">779,277</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,348,177\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,348,177</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,348,177\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,348,177</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1642 - loss: 8.0836\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.1658 - loss: 8.1606\n",
            "\n",
            "Epoch 2/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0494 - loss: 7.4824\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.0498 - loss: 7.5537\n",
            "\n",
            "Epoch 3/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0536 - loss: 7.1354\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.0541 - loss: 7.2033\n",
            "\n",
            "Epoch 4/30\n",
            "106/105 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.0556 - loss: 6.9033\n",
            "105/105 ━━━━━━━━━━━━━ 216s total - accuracy: 0.0561 - loss: 6.9690\n",
            "\n",
            "Epoch 5/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0590 - loss: 6.7352\n",
            "105/105 ━━━━━━━━━━━━━ 27s total - accuracy: 0.0596 - loss: 6.7993\n",
            "\n",
            "Epoch 6/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0622 - loss: 6.5980\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.0628 - loss: 6.6608\n",
            "\n",
            "Epoch 7/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0656 - loss: 6.4741\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.0662 - loss: 6.5357\n",
            "\n",
            "Epoch 8/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0696 - loss: 6.3537\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.0703 - loss: 6.4142\n",
            "\n",
            "Epoch 9/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0744 - loss: 6.2321\n",
            "105/105 ━━━━━━━━━━━━━ 34s total - accuracy: 0.0751 - loss: 6.2914\n",
            "\n",
            "Epoch 10/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0802 - loss: 6.1057\n",
            "105/105 ━━━━━━━━━━━━━ 36s total - accuracy: 0.0810 - loss: 6.1638\n",
            "\n",
            "Epoch 11/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0891 - loss: 5.9728\n",
            "105/105 ━━━━━━━━━━━━━ 38s total - accuracy: 0.0900 - loss: 6.0297\n",
            "\n",
            "Epoch 12/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1016 - loss: 5.8331\n",
            "105/105 ━━━━━━━━━━━━━ 40s total - accuracy: 0.1025 - loss: 5.8887\n",
            "\n",
            "Epoch 13/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1174 - loss: 5.6879\n",
            "105/105 ━━━━━━━━━━━━━ 40s total - accuracy: 0.1186 - loss: 5.7421\n",
            "\n",
            "Epoch 14/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1365 - loss: 5.5386\n",
            "105/105 ━━━━━━━━━━━━━ 40s total - accuracy: 0.1378 - loss: 5.5913\n",
            "\n",
            "Epoch 15/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1576 - loss: 5.3866\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.1591 - loss: 5.4379\n",
            "\n",
            "Epoch 16/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1802 - loss: 5.2331\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.1819 - loss: 5.2830\n",
            "\n",
            "Epoch 17/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2040 - loss: 5.0796\n",
            "105/105 ━━━━━━━━━━━━━ 41s total - accuracy: 0.2060 - loss: 5.1280\n",
            "\n",
            "Epoch 18/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2285 - loss: 4.9276\n",
            "105/105 ━━━━━━━━━━━━━ 41s total - accuracy: 0.2307 - loss: 4.9745\n",
            "\n",
            "Epoch 19/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2534 - loss: 4.7784\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.2558 - loss: 4.8239\n",
            "\n",
            "Epoch 20/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2790 - loss: 4.6322\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.2816 - loss: 4.6763\n",
            "\n",
            "Epoch 21/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3048 - loss: 4.4897\n",
            "105/105 ━━━━━━━━━━━━━ 43s total - accuracy: 0.3077 - loss: 4.5325\n",
            "\n",
            "Epoch 22/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3306 - loss: 4.3513\n",
            "105/105 ━━━━━━━━━━━━━ 44s total - accuracy: 0.3337 - loss: 4.3928\n",
            "\n",
            "Epoch 23/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3559 - loss: 4.2172\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.3593 - loss: 4.2574\n",
            "\n",
            "Epoch 24/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3805 - loss: 4.0880\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.3841 - loss: 4.1269\n",
            "\n",
            "Epoch 25/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4040 - loss: 3.9637\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.4079 - loss: 4.0015\n",
            "\n",
            "Epoch 26/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4263 - loss: 3.8443\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.4303 - loss: 3.8809\n",
            "\n",
            "Epoch 27/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4473 - loss: 3.7296\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4516 - loss: 3.7651\n",
            "\n",
            "Epoch 28/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4671 - loss: 3.6194\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4715 - loss: 3.6539\n",
            "\n",
            "Epoch 29/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4855 - loss: 3.5136\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4902 - loss: 3.5471\n",
            "\n",
            "Epoch 30/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5029 - loss: 3.4121\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.5077 - loss: 3.4446\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0491, 0.4911, 0.4911, 0.0620)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_model1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "\n",
        "# Calculate vocabulary size dynamically\n",
        "vocab_size = max(np.max(X_train), np.max(X_test), np.max(y_train), np.max(y_test)) + 1\n",
        "print(f\"Updated Vocabulary Size: {vocab_size}\")\n",
        "\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "# Hyperparameters for Model 4\n",
        "embedding_dim = 200  # Embedding dimension\n",
        "hidden_units = 400  # GRU units\n",
        "sequence_length = 20  # Sequence length\n",
        "batch_size = 32  # Batch size\n",
        "epochs = 30  # Number of epochs\n",
        "learning_rate = 0.0007  # Learning rate\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=vocab_size, activation='softmax')  # Match vocabulary size\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, \"evaluation_results_model4.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, 'evaluation_results_model4.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hbvowFLrgEaa",
        "outputId": "530a57bb-567a-4042-cc25-b2746e9e3563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Vocabulary Size: 3877\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m200\u001b[0m)             │         \u001b[38;5;34m775,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 │         \u001b[38;5;34m722,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3877\u001b[0m)                │       \u001b[38;5;34m1,554,677\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">775,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">722,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3877</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,554,677</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,052,477\u001b[0m (11.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,477</span> (11.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,052,477\u001b[0m (11.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,477</span> (11.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "4/105 ━━━━━━━━━━━━━ 35s remaining - accuracy: 0.2760 - loss: 8.2491WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000022B3FDBC310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/105 ━━━━━━━━━━━━━ 32s remaining - accuracy: 0.3171 - loss: 8.2442WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000022B3FDBC310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1842 - loss: 7.9842\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.1860 - loss: 8.0602\n",
            "\n",
            "Epoch 2/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0703 - loss: 7.2537\n",
            "105/105 ━━━━━━━━━━━━━ 36s total - accuracy: 0.0710 - loss: 7.3228\n",
            "\n",
            "Epoch 3/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0726 - loss: 6.8093\n",
            "105/105 ━━━━━━━━━━━━━ 40s total - accuracy: 0.0733 - loss: 6.8741\n",
            "\n",
            "Epoch 4/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0786 - loss: 6.5019\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.0794 - loss: 6.5638\n",
            "\n",
            "Epoch 5/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.0885 - loss: 6.2512\n",
            "105/105 ━━━━━━━━━━━━━ 43s total - accuracy: 0.0893 - loss: 6.3108\n",
            "\n",
            "Epoch 6/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1044 - loss: 6.0188\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.1054 - loss: 6.0761\n",
            "\n",
            "Epoch 7/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1258 - loss: 5.7835\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.1270 - loss: 5.8386\n",
            "\n",
            "Epoch 8/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1515 - loss: 5.5472\n",
            "105/105 ━━━━━━━━━━━━━ 48s total - accuracy: 0.1529 - loss: 5.6000\n",
            "\n",
            "Epoch 9/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1830 - loss: 5.2982\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.1848 - loss: 5.3487\n",
            "\n",
            "Epoch 10/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2170 - loss: 5.0549\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.2191 - loss: 5.1030\n",
            "\n",
            "Epoch 11/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2514 - loss: 4.8206\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.2538 - loss: 4.8665\n",
            "\n",
            "Epoch 12/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2908 - loss: 4.5717\n",
            "105/105 ━━━━━━━━━━━━━ 55s total - accuracy: 0.2936 - loss: 4.6153\n",
            "\n",
            "Epoch 13/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3345 - loss: 4.3179\n",
            "105/105 ━━━━━━━━━━━━━ 57s total - accuracy: 0.3377 - loss: 4.3590\n",
            "\n",
            "Epoch 14/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3792 - loss: 4.0683\n",
            "105/105 ━━━━━━━━━━━━━ 60s total - accuracy: 0.3828 - loss: 4.1070\n",
            "\n",
            "Epoch 15/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4212 - loss: 3.8304\n",
            "105/105 ━━━━━━━━━━━━━ 62s total - accuracy: 0.4252 - loss: 3.8669\n",
            "\n",
            "Epoch 16/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4585 - loss: 3.6075\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.4628 - loss: 3.6419\n",
            "\n",
            "Epoch 17/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4913 - loss: 3.4026\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.4960 - loss: 3.4350\n",
            "\n",
            "Epoch 18/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5204 - loss: 3.2164\n",
            "105/105 ━━━━━━━━━━━━━ 69s total - accuracy: 0.5253 - loss: 3.2470\n",
            "\n",
            "Epoch 19/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5463 - loss: 3.0477\n",
            "105/105 ━━━━━━━━━━━━━ 72s total - accuracy: 0.5515 - loss: 3.0768\n",
            "\n",
            "Epoch 20/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5696 - loss: 2.8951\n",
            "105/105 ━━━━━━━━━━━━━ 73s total - accuracy: 0.5750 - loss: 2.9227\n",
            "\n",
            "Epoch 21/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5906 - loss: 2.7566\n",
            "105/105 ━━━━━━━━━━━━━ 76s total - accuracy: 0.5962 - loss: 2.7829\n",
            "\n",
            "Epoch 22/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6096 - loss: 2.6305\n",
            "105/105 ━━━━━━━━━━━━━ 79s total - accuracy: 0.6154 - loss: 2.6555\n",
            "\n",
            "Epoch 23/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6270 - loss: 2.5152\n",
            "105/105 ━━━━━━━━━━━━━ 80s total - accuracy: 0.6329 - loss: 2.5392\n",
            "\n",
            "Epoch 24/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6428 - loss: 2.4096\n",
            "105/105 ━━━━━━━━━━━━━ 82s total - accuracy: 0.6489 - loss: 2.4325\n",
            "\n",
            "Epoch 25/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6574 - loss: 2.3123\n",
            "105/105 ━━━━━━━━━━━━━ 85s total - accuracy: 0.6637 - loss: 2.3344\n",
            "\n",
            "Epoch 26/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6708 - loss: 2.2226\n",
            "105/105 ━━━━━━━━━━━━━ 87s total - accuracy: 0.6772 - loss: 2.2438\n",
            "\n",
            "Epoch 27/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6833 - loss: 2.1395\n",
            "105/105 ━━━━━━━━━━━━━ 92s total - accuracy: 0.6898 - loss: 2.1599\n",
            "\n",
            "Epoch 28/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6948 - loss: 2.0624\n",
            "105/105 ━━━━━━━━━━━━━ 93s total - accuracy: 0.7014 - loss: 2.0820\n",
            "\n",
            "Epoch 29/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7055 - loss: 1.9906\n",
            "105/105 ━━━━━━━━━━━━━ 95s total - accuracy: 0.7122 - loss: 2.0096\n",
            "\n",
            "Epoch 30/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7155 - loss: 1.9236\n",
            "105/105 ━━━━━━━━━━━━━ 100s total - accuracy: 0.7223 - loss: 1.9420\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0571, 0.5706, 0.5706, 0.0651)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_model4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Load preprocessed data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Hyperparameters for Experiment 1\n",
        "embedding_dim = 100  # Modify for each experiment\n",
        "hidden_units = 200  # Modify for each experiment\n",
        "sequence_length = 20  # Modify for each experiment\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "learning_rate = 0.001  # Modify for each experiment\n",
        "dropout_rate = 0.3  # Modify for each experiment\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=dropout_rate),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        step_start_time = time.time()\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target)\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, \"evaluation_results_experiment1.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, 'evaluation_results_experiment1.csv')}\")\n"
      ],
      "metadata": {
        "id": "Kym2oPB8dtx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00cff27e-63d4-4e19-a529-e0eb0cc45883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │         \u001b[38;5;34m332,300\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │         \u001b[38;5;34m181,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │         \u001b[38;5;34m667,923\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">332,300</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">181,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">667,923</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,181,423\u001b[0m (4.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,423</span> (4.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,181,423\u001b[0m (4.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,181,423</span> (4.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2408 - loss: 7.3538\n",
            "105/105 ━━━━━━━━━━━━━ 21s total - accuracy: 0.2431 - loss: 7.4239\n",
            "\n",
            "Epoch 2/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1668 - loss: 6.3357\n",
            "105/105 ━━━━━━━━━━━━━ 21s total - accuracy: 0.1684 - loss: 6.3961\n",
            "\n",
            "Epoch 3/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1722 - loss: 5.8715\n",
            "105/105 ━━━━━━━━━━━━━ 20s total - accuracy: 0.1739 - loss: 5.9274\n",
            "\n",
            "Epoch 4/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1893 - loss: 5.5651\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.1911 - loss: 5.6181\n",
            "\n",
            "Epoch 5/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2021 - loss: 5.3197\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.2041 - loss: 5.3703\n",
            "\n",
            "Epoch 6/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2148 - loss: 5.0968\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.2168 - loss: 5.1453\n",
            "\n",
            "Epoch 7/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2306 - loss: 4.8810\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.2328 - loss: 4.9275\n",
            "\n",
            "Epoch 8/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2498 - loss: 4.6684\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.2522 - loss: 4.7129\n",
            "\n",
            "Epoch 9/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2726 - loss: 4.4578\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.2752 - loss: 4.5003\n",
            "\n",
            "Epoch 10/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2983 - loss: 4.2493\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.3012 - loss: 4.2898\n",
            "\n",
            "Epoch 11/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3283 - loss: 4.0435\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.3314 - loss: 4.0821\n",
            "\n",
            "Epoch 12/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3617 - loss: 3.8419\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.3652 - loss: 3.8785\n",
            "\n",
            "Epoch 13/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3973 - loss: 3.6466\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.4011 - loss: 3.6813\n",
            "\n",
            "Epoch 14/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4333 - loss: 3.4588\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.4375 - loss: 3.4917\n",
            "\n",
            "Epoch 15/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4678 - loss: 3.2801\n",
            "105/105 ━━━━━━━━━━━━━ 27s total - accuracy: 0.4723 - loss: 3.3114\n",
            "\n",
            "Epoch 16/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4998 - loss: 3.1116\n",
            "105/105 ━━━━━━━━━━━━━ 28s total - accuracy: 0.5045 - loss: 3.1412\n",
            "\n",
            "Epoch 17/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5290 - loss: 2.9537\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.5340 - loss: 2.9818\n",
            "\n",
            "Epoch 18/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5553 - loss: 2.8068\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.5606 - loss: 2.8335\n",
            "\n",
            "Epoch 19/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5791 - loss: 2.6708\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.5847 - loss: 2.6962\n",
            "\n",
            "Epoch 20/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6006 - loss: 2.5452\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.6064 - loss: 2.5694\n",
            "\n",
            "Epoch 21/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6201 - loss: 2.4296\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.6260 - loss: 2.4528\n",
            "\n",
            "Epoch 22/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6377 - loss: 2.3231\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.6438 - loss: 2.3452\n",
            "\n",
            "Epoch 23/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6538 - loss: 2.2248\n",
            "105/105 ━━━━━━━━━━━━━ 31s total - accuracy: 0.6601 - loss: 2.2460\n",
            "\n",
            "Epoch 24/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6686 - loss: 2.1341\n",
            "105/105 ━━━━━━━━━━━━━ 32s total - accuracy: 0.6749 - loss: 2.1544\n",
            "\n",
            "Epoch 25/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6821 - loss: 2.0502\n",
            "105/105 ━━━━━━━━━━━━━ 32s total - accuracy: 0.6886 - loss: 2.0697\n",
            "\n",
            "Epoch 26/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6945 - loss: 1.9724\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.7011 - loss: 1.9912\n",
            "\n",
            "Epoch 27/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7060 - loss: 1.9001\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.7128 - loss: 1.9182\n",
            "\n",
            "Epoch 28/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7167 - loss: 1.8328\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.7236 - loss: 1.8503\n",
            "\n",
            "Epoch 29/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7267 - loss: 1.7701\n",
            "105/105 ━━━━━━━━━━━━━ 34s total - accuracy: 0.7336 - loss: 1.7869\n",
            "\n",
            "Epoch 30/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7359 - loss: 1.7114\n",
            "105/105 ━━━━━━━━━━━━━ 35s total - accuracy: 0.7429 - loss: 1.7277\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0568, 0.5682, 0.5682, 0.0638)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 300  # Adjust embedding dimension\n",
        "hidden_units = 500  # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 32      # Adjust batch size\n",
        "epochs = 30          # Increase number of epochs\n",
        "learning_rate = 0.0002  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PxHKaO0YuL_L",
        "outputId": "3e6620bd-bacc-4999-e4f0-f814432071f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │         \u001b[38;5;34m996,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │       \u001b[38;5;34m1,203,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,664,823\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">996,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,203,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664,823</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,864,723\u001b[0m (14.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,864,723</span> (14.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,864,723\u001b[0m (14.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,864,723</span> (14.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "4/105 ━━━━━━━━━━━━━ 36s remaining - accuracy: 0.0872 - loss: 8.1051WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000136DCFB3130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "5/105 ━━━━━━━━━━━━━ 33s remaining - accuracy: 0.1335 - loss: 8.1029WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000136DCFB3130> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2120 - loss: 7.7289\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.2140 - loss: 7.8025\n",
            "\n",
            "Epoch 2/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1615 - loss: 6.7314\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.1630 - loss: 6.7956\n",
            "\n",
            "Epoch 3/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1827 - loss: 6.2540\n",
            "105/105 ━━━━━━━━━━━━━ 22s total - accuracy: 0.1845 - loss: 6.3136\n",
            "\n",
            "Epoch 4/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1962 - loss: 5.9750\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.1981 - loss: 6.0319\n",
            "\n",
            "Epoch 5/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2054 - loss: 5.7815\n",
            "105/105 ━━━━━━━━━━━━━ 23s total - accuracy: 0.2074 - loss: 5.8365\n",
            "\n",
            "Epoch 6/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2115 - loss: 5.6287\n",
            "105/105 ━━━━━━━━━━━━━ 24s total - accuracy: 0.2135 - loss: 5.6823\n",
            "\n",
            "Epoch 7/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2182 - loss: 5.4942\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.2203 - loss: 5.5466\n",
            "\n",
            "Epoch 8/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2253 - loss: 5.3676\n",
            "105/105 ━━━━━━━━━━━━━ 25s total - accuracy: 0.2274 - loss: 5.4187\n",
            "\n",
            "Epoch 9/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2332 - loss: 5.2438\n",
            "105/105 ━━━━━━━━━━━━━ 27s total - accuracy: 0.2354 - loss: 5.2938\n",
            "\n",
            "Epoch 10/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2421 - loss: 5.1202\n",
            "105/105 ━━━━━━━━━━━━━ 29s total - accuracy: 0.2445 - loss: 5.1690\n",
            "\n",
            "Epoch 11/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2519 - loss: 4.9958\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.2543 - loss: 5.0434\n",
            "\n",
            "Epoch 12/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2630 - loss: 4.8704\n",
            "105/105 ━━━━━━━━━━━━━ 32s total - accuracy: 0.2655 - loss: 4.9168\n",
            "\n",
            "Epoch 13/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2756 - loss: 4.7443\n",
            "105/105 ━━━━━━━━━━━━━ 33s total - accuracy: 0.2782 - loss: 4.7895\n",
            "\n",
            "Epoch 14/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2895 - loss: 4.6179\n",
            "105/105 ━━━━━━━━━━━━━ 35s total - accuracy: 0.2923 - loss: 4.6619\n",
            "\n",
            "Epoch 15/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3046 - loss: 4.4916\n",
            "105/105 ━━━━━━━━━━━━━ 37s total - accuracy: 0.3075 - loss: 4.5344\n",
            "\n",
            "Epoch 16/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3211 - loss: 4.3657\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.3242 - loss: 4.4073\n",
            "\n",
            "Epoch 17/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3391 - loss: 4.2407\n",
            "105/105 ━━━━━━━━━━━━━ 41s total - accuracy: 0.3423 - loss: 4.2811\n",
            "\n",
            "Epoch 18/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3586 - loss: 4.1170\n",
            "105/105 ━━━━━━━━━━━━━ 43s total - accuracy: 0.3620 - loss: 4.1562\n",
            "\n",
            "Epoch 19/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3795 - loss: 3.9950\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.3831 - loss: 4.0331\n",
            "\n",
            "Epoch 20/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4014 - loss: 3.8751\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4053 - loss: 3.9120\n",
            "\n",
            "Epoch 21/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4236 - loss: 3.7577\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.4277 - loss: 3.7935\n",
            "\n",
            "Epoch 22/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4456 - loss: 3.6435\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.4498 - loss: 3.6782\n",
            "\n",
            "Epoch 23/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4671 - loss: 3.5321\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.4716 - loss: 3.5657\n",
            "\n",
            "Epoch 24/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4881 - loss: 3.4233\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.4927 - loss: 3.4559\n",
            "\n",
            "Epoch 25/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5080 - loss: 3.3174\n",
            "105/105 ━━━━━━━━━━━━━ 56s total - accuracy: 0.5128 - loss: 3.3490\n",
            "\n",
            "Epoch 26/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5268 - loss: 3.2151\n",
            "105/105 ━━━━━━━━━━━━━ 58s total - accuracy: 0.5318 - loss: 3.2457\n",
            "\n",
            "Epoch 27/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5444 - loss: 3.1164\n",
            "105/105 ━━━━━━━━━━━━━ 61s total - accuracy: 0.5496 - loss: 3.1461\n",
            "\n",
            "Epoch 28/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5609 - loss: 3.0216\n",
            "105/105 ━━━━━━━━━━━━━ 62s total - accuracy: 0.5662 - loss: 3.0504\n",
            "\n",
            "Epoch 29/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5762 - loss: 2.9308\n",
            "105/105 ━━━━━━━━━━━━━ 64s total - accuracy: 0.5817 - loss: 2.9587\n",
            "\n",
            "Epoch 30/30\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5906 - loss: 2.8439\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.5962 - loss: 2.8710\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0464, 0.4638, 0.4638, 0.0569)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_300_500_30.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 250  # Adjust embedding dimension\n",
        "hidden_units = 350   # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 32      # Adjust batch size\n",
        "epochs = 35         # Increase number of epochs\n",
        "learning_rate = 0.0002  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wx30q8t4tqei",
        "outputId": "758a6c32-b859-4d01-ad20-08050b05f393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m250\u001b[0m)             │         \u001b[38;5;34m830,750\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m)                 │         \u001b[38;5;34m632,100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,166,373\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">830,750</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">632,100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,166,373</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,629,223\u001b[0m (10.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,629,223</span> (10.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,629,223\u001b[0m (10.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,629,223</span> (10.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2014 - loss: 7.8500\n",
            "105/105 ━━━━━━━━━━━━━ 37s total - accuracy: 0.2033 - loss: 7.9247\n",
            "\n",
            "Epoch 2/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1650 - loss: 6.8745\n",
            "105/105 ━━━━━━━━━━━━━ 36s total - accuracy: 0.1665 - loss: 6.9400\n",
            "\n",
            "Epoch 3/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1850 - loss: 6.3547\n",
            "105/105 ━━━━━━━━━━━━━ 38s total - accuracy: 0.1867 - loss: 6.4153\n",
            "\n",
            "Epoch 4/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1960 - loss: 6.0716\n",
            "105/105 ━━━━━━━━━━━━━ 38s total - accuracy: 0.1979 - loss: 6.1295\n",
            "\n",
            "Epoch 5/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2042 - loss: 5.8732\n",
            "105/105 ━━━━━━━━━━━━━ 38s total - accuracy: 0.2062 - loss: 5.9291\n",
            "\n",
            "Epoch 6/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2103 - loss: 5.7187\n",
            "105/105 ━━━━━━━━━━━━━ 38s total - accuracy: 0.2124 - loss: 5.7732\n",
            "\n",
            "Epoch 7/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2147 - loss: 5.5883\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.2167 - loss: 5.6416\n",
            "\n",
            "Epoch 8/35\n",
            "106/105 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2191 - loss: 5.4716\n",
            "105/105 ━━━━━━━━━━━━━ 239s total - accuracy: 0.2211 - loss: 5.5237\n",
            "\n",
            "Epoch 9/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2244 - loss: 5.3623\n",
            "105/105 ━━━━━━━━━━━━━ 36s total - accuracy: 0.2265 - loss: 5.4134\n",
            "\n",
            "Epoch 10/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2301 - loss: 5.2569\n",
            "105/105 ━━━━━━━━━━━━━ 35s total - accuracy: 0.2322 - loss: 5.3070\n",
            "\n",
            "Epoch 11/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2367 - loss: 5.1533\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.2390 - loss: 5.2024\n",
            "\n",
            "Epoch 12/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2442 - loss: 5.0505\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.2465 - loss: 5.0986\n",
            "\n",
            "Epoch 13/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2525 - loss: 4.9480\n",
            "105/105 ━━━━━━━━━━━━━ 43s total - accuracy: 0.2549 - loss: 4.9952\n",
            "\n",
            "Epoch 14/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2616 - loss: 4.8459\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.2641 - loss: 4.8921\n",
            "\n",
            "Epoch 15/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2713 - loss: 4.7440\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.2739 - loss: 4.7892\n",
            "\n",
            "Epoch 16/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2822 - loss: 4.6425\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.2849 - loss: 4.6867\n",
            "\n",
            "Epoch 17/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2939 - loss: 4.5416\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.2967 - loss: 4.5848\n",
            "\n",
            "Epoch 18/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3064 - loss: 4.4414\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.3093 - loss: 4.4837\n",
            "\n",
            "Epoch 19/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3196 - loss: 4.3421\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.3227 - loss: 4.3835\n",
            "\n",
            "Epoch 20/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3337 - loss: 4.2440\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.3369 - loss: 4.2844\n",
            "\n",
            "Epoch 21/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3486 - loss: 4.1471\n",
            "105/105 ━━━━━━━━━━━━━ 55s total - accuracy: 0.3519 - loss: 4.1866\n",
            "\n",
            "Epoch 22/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3641 - loss: 4.0515\n",
            "105/105 ━━━━━━━━━━━━━ 55s total - accuracy: 0.3675 - loss: 4.0901\n",
            "\n",
            "Epoch 23/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3802 - loss: 3.9574\n",
            "105/105 ━━━━━━━━━━━━━ 57s total - accuracy: 0.3838 - loss: 3.9951\n",
            "\n",
            "Epoch 24/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3970 - loss: 3.8649\n",
            "105/105 ━━━━━━━━━━━━━ 57s total - accuracy: 0.4008 - loss: 3.9017\n",
            "\n",
            "Epoch 25/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4142 - loss: 3.7740\n",
            "105/105 ━━━━━━━━━━━━━ 58s total - accuracy: 0.4182 - loss: 3.8099\n",
            "\n",
            "Epoch 26/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4316 - loss: 3.6849\n",
            "105/105 ━━━━━━━━━━━━━ 60s total - accuracy: 0.4357 - loss: 3.7200\n",
            "\n",
            "Epoch 27/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4490 - loss: 3.5976\n",
            "105/105 ━━━━━━━━━━━━━ 61s total - accuracy: 0.4533 - loss: 3.6318\n",
            "\n",
            "Epoch 28/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4662 - loss: 3.5121\n",
            "105/105 ━━━━━━━━━━━━━ 62s total - accuracy: 0.4706 - loss: 3.5456\n",
            "\n",
            "Epoch 29/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4829 - loss: 3.4286\n",
            "105/105 ━━━━━━━━━━━━━ 65s total - accuracy: 0.4875 - loss: 3.4613\n",
            "\n",
            "Epoch 30/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4991 - loss: 3.3471\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.5039 - loss: 3.3789\n",
            "\n",
            "Epoch 31/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5147 - loss: 3.2677\n",
            "105/105 ━━━━━━━━━━━━━ 67s total - accuracy: 0.5196 - loss: 3.2988\n",
            "\n",
            "Epoch 32/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5295 - loss: 3.1903\n",
            "105/105 ━━━━━━━━━━━━━ 68s total - accuracy: 0.5345 - loss: 3.2207\n",
            "\n",
            "Epoch 33/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5436 - loss: 3.1152\n",
            "105/105 ━━━━━━━━━━━━━ 68s total - accuracy: 0.5487 - loss: 3.1448\n",
            "\n",
            "Epoch 34/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5569 - loss: 3.0422\n",
            "105/105 ━━━━━━━━━━━━━ 71s total - accuracy: 0.5622 - loss: 3.0712\n",
            "\n",
            "Epoch 35/35\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5696 - loss: 2.9715\n",
            "105/105 ━━━━━━━━━━━━━ 73s total - accuracy: 0.5750 - loss: 2.9998\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0496, 0.4958, 0.4958, 0.0621)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_250_350_35.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 250  # Adjust embedding dimension\n",
        "hidden_units = 400   # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 32      # Adjust batch size\n",
        "epochs = 40          # Increase number of epochs\n",
        "learning_rate = 0.0003  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sbOE_K9-tWOS",
        "outputId": "6a65a601-fda3-4e4e-a4e5-16c85989dfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m250\u001b[0m)             │         \u001b[38;5;34m830,750\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 │         \u001b[38;5;34m782,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,332,523\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">830,750</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">782,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,332,523</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945,673\u001b[0m (11.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945,673</span> (11.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,945,673\u001b[0m (11.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945,673</span> (11.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2113 - loss: 7.5912\n",
            "105/105 ━━━━━━━━━━━━━ 57s total - accuracy: 0.2133 - loss: 7.6635\n",
            "\n",
            "Epoch 2/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1582 - loss: 6.5884\n",
            "105/105 ━━━━━━━━━━━━━ 64s total - accuracy: 0.1597 - loss: 6.6511\n",
            "\n",
            "Epoch 3/40\n",
            "106/105 ━━━━━━━━━━━━━ -3s remaining - accuracy: 0.1810 - loss: 6.1191\n",
            "105/105 ━━━━━━━━━━━━━ 396s total - accuracy: 0.1827 - loss: 6.1774\n",
            "\n",
            "Epoch 4/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1949 - loss: 5.8362\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.1968 - loss: 5.8918\n",
            "\n",
            "Epoch 5/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2046 - loss: 5.6328\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.2065 - loss: 5.6864\n",
            "\n",
            "Epoch 6/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2127 - loss: 5.4645\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.2147 - loss: 5.5166\n",
            "\n",
            "Epoch 7/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2213 - loss: 5.3102\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.2234 - loss: 5.3608\n",
            "\n",
            "Epoch 8/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2308 - loss: 5.1595\n",
            "105/105 ━━━━━━━━━━━━━ 48s total - accuracy: 0.2330 - loss: 5.2086\n",
            "\n",
            "Epoch 9/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2422 - loss: 5.0081\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.2445 - loss: 5.0558\n",
            "\n",
            "Epoch 10/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2561 - loss: 4.8556\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.2585 - loss: 4.9019\n",
            "\n",
            "Epoch 11/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2723 - loss: 4.7021\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.2749 - loss: 4.7469\n",
            "\n",
            "Epoch 12/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2905 - loss: 4.5481\n",
            "105/105 ━━━━━━━━━━━━━ 58s total - accuracy: 0.2932 - loss: 4.5914\n",
            "\n",
            "Epoch 13/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3106 - loss: 4.3941\n",
            "105/105 ━━━━━━━━━━━━━ 62s total - accuracy: 0.3135 - loss: 4.4360\n",
            "\n",
            "Epoch 14/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3326 - loss: 4.2413\n",
            "105/105 ━━━━━━━━━━━━━ 64s total - accuracy: 0.3357 - loss: 4.2817\n",
            "\n",
            "Epoch 15/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3559 - loss: 4.0906\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.3593 - loss: 4.1296\n",
            "\n",
            "Epoch 16/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3803 - loss: 3.9427\n",
            "105/105 ━━━━━━━━━━━━━ 69s total - accuracy: 0.3839 - loss: 3.9803\n",
            "\n",
            "Epoch 17/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4057 - loss: 3.7986\n",
            "105/105 ━━━━━━━━━━━━━ 69s total - accuracy: 0.4096 - loss: 3.8348\n",
            "\n",
            "Epoch 18/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4317 - loss: 3.6586\n",
            "105/105 ━━━━━━━━━━━━━ 66s total - accuracy: 0.4358 - loss: 3.6935\n",
            "\n",
            "Epoch 19/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4576 - loss: 3.5231\n",
            "105/105 ━━━━━━━━━━━━━ 69s total - accuracy: 0.4620 - loss: 3.5566\n",
            "\n",
            "Epoch 20/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4827 - loss: 3.3921\n",
            "105/105 ━━━━━━━━━━━━━ 74s total - accuracy: 0.4873 - loss: 3.4244\n",
            "\n",
            "Epoch 21/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5063 - loss: 3.2659\n",
            "105/105 ━━━━━━━━━━━━━ 76s total - accuracy: 0.5112 - loss: 3.2971\n",
            "\n",
            "Epoch 22/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5285 - loss: 3.1451\n",
            "105/105 ━━━━━━━━━━━━━ 78s total - accuracy: 0.5335 - loss: 3.1751\n",
            "\n",
            "Epoch 23/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5491 - loss: 3.0296\n",
            "105/105 ━━━━━━━━━━━━━ 81s total - accuracy: 0.5543 - loss: 3.0585\n",
            "\n",
            "Epoch 24/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5681 - loss: 2.9198\n",
            "105/105 ━━━━━━━━━━━━━ 85s total - accuracy: 0.5735 - loss: 2.9476\n",
            "\n",
            "Epoch 25/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5857 - loss: 2.8156\n",
            "105/105 ━━━━━━━━━━━━━ 89s total - accuracy: 0.5912 - loss: 2.8424\n",
            "\n",
            "Epoch 26/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6019 - loss: 2.7170\n",
            "105/105 ━━━━━━━━━━━━━ 93s total - accuracy: 0.6076 - loss: 2.7428\n",
            "\n",
            "Epoch 27/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6169 - loss: 2.6238\n",
            "105/105 ━━━━━━━━━━━━━ 98s total - accuracy: 0.6228 - loss: 2.6488\n",
            "\n",
            "Epoch 28/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6308 - loss: 2.5359\n",
            "105/105 ━━━━━━━━━━━━━ 101s total - accuracy: 0.6368 - loss: 2.5600\n",
            "\n",
            "Epoch 29/40\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6438 - loss: 2.4529\n",
            "105/105 ━━━━━━━━━━━━━ 104s total - accuracy: 0.6499 - loss: 2.4763\n",
            "\n",
            "Epoch 30/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6558 - loss: 2.3747\n",
            "105/105 ━━━━━━━━━━━━━ 108s total - accuracy: 0.6621 - loss: 2.3973\n",
            "\n",
            "Epoch 31/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6671 - loss: 2.3009\n",
            "105/105 ━━━━━━━━━━━━━ 112s total - accuracy: 0.6735 - loss: 2.3229\n",
            "\n",
            "Epoch 32/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6777 - loss: 2.2313\n",
            "105/105 ━━━━━━━━━━━━━ 115s total - accuracy: 0.6841 - loss: 2.2525\n",
            "\n",
            "Epoch 33/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6876 - loss: 2.1654\n",
            "105/105 ━━━━━━━━━━━━━ 118s total - accuracy: 0.6942 - loss: 2.1861\n",
            "\n",
            "Epoch 34/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6969 - loss: 2.1032\n",
            "105/105 ━━━━━━━━━━━━━ 123s total - accuracy: 0.7036 - loss: 2.1232\n",
            "\n",
            "Epoch 35/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7057 - loss: 2.0443\n",
            "105/105 ━━━━━━━━━━━━━ 124s total - accuracy: 0.7124 - loss: 2.0637\n",
            "\n",
            "Epoch 36/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7140 - loss: 1.9884\n",
            "105/105 ━━━━━━━━━━━━━ 127s total - accuracy: 0.7208 - loss: 2.0074\n",
            "\n",
            "Epoch 37/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7218 - loss: 1.9355\n",
            "105/105 ━━━━━━━━━━━━━ 132s total - accuracy: 0.7287 - loss: 1.9539\n",
            "\n",
            "Epoch 38/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7293 - loss: 1.8852\n",
            "105/105 ━━━━━━━━━━━━━ 134s total - accuracy: 0.7362 - loss: 1.9031\n",
            "\n",
            "Epoch 39/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7363 - loss: 1.8373\n",
            "105/105 ━━━━━━━━━━━━━ 139s total - accuracy: 0.7433 - loss: 1.8548\n",
            "\n",
            "Epoch 40/40\n",
            "106/105 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.7430 - loss: 1.7918\n",
            "105/105 ━━━━━━━━━━━━━ 142s total - accuracy: 0.7500 - loss: 1.8089\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0527, 0.5267, 0.5267, 0.0620)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_250_400_40.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 150 # Adjust embedding dimension\n",
        "hidden_units = 300   # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 32      # Adjust batch size\n",
        "epochs = 50          # Increase number of epochs\n",
        "learning_rate = 0.0005  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1xELP2wHtihU",
        "outputId": "5e5b2d8e-6951-43e5-c0a1-fa524c390063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m150\u001b[0m)             │         \u001b[38;5;34m498,450\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │         \u001b[38;5;34m406,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,000,223\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">498,450</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">406,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,223</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,905,473\u001b[0m (7.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,905,473</span> (7.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,905,473\u001b[0m (7.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,905,473</span> (7.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2233 - loss: 7.5001\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.2255 - loss: 7.5715\n",
            "\n",
            "Epoch 2/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1617 - loss: 6.4951\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.1632 - loss: 6.5570\n",
            "\n",
            "Epoch 3/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1733 - loss: 6.0162\n",
            "105/105 ━━━━━━━━━━━━━ 50s total - accuracy: 0.1750 - loss: 6.0735\n",
            "\n",
            "Epoch 4/50\n",
            "106/105 ━━━━━━━━━━━━━ -5s remaining - accuracy: 0.1888 - loss: 5.7242\n",
            "105/105 ━━━━━━━━━━━━━ 534s total - accuracy: 0.1906 - loss: 5.7787\n",
            "\n",
            "Epoch 5/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1999 - loss: 5.5027\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.2018 - loss: 5.5551\n",
            "\n",
            "Epoch 6/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2095 - loss: 5.3053\n",
            "105/105 ━━━━━━━━━━━━━ 26s total - accuracy: 0.2115 - loss: 5.3559\n",
            "\n",
            "Epoch 7/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2203 - loss: 5.1145\n",
            "105/105 ━━━━━━━━━━━━━ 30s total - accuracy: 0.2224 - loss: 5.1632\n",
            "\n",
            "Epoch 8/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2333 - loss: 4.9258\n",
            "105/105 ━━━━━━━━━━━━━ 34s total - accuracy: 0.2356 - loss: 4.9728\n",
            "\n",
            "Epoch 9/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2497 - loss: 4.7383\n",
            "105/105 ━━━━━━━━━━━━━ 36s total - accuracy: 0.2521 - loss: 4.7835\n",
            "\n",
            "Epoch 10/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2693 - loss: 4.5520\n",
            "105/105 ━━━━━━━━━━━━━ 39s total - accuracy: 0.2719 - loss: 4.5954\n",
            "\n",
            "Epoch 11/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2916 - loss: 4.3674\n",
            "105/105 ━━━━━━━━━━━━━ 41s total - accuracy: 0.2943 - loss: 4.4090\n",
            "\n",
            "Epoch 12/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3168 - loss: 4.1859\n",
            "105/105 ━━━━━━━━━━━━━ 42s total - accuracy: 0.3198 - loss: 4.2257\n",
            "\n",
            "Epoch 13/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3454 - loss: 4.0085\n",
            "105/105 ━━━━━━━━━━━━━ 44s total - accuracy: 0.3487 - loss: 4.0467\n",
            "\n",
            "Epoch 14/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.3761 - loss: 3.8367\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.3797 - loss: 3.8733\n",
            "\n",
            "Epoch 15/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4077 - loss: 3.6706\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.4116 - loss: 3.7056\n",
            "\n",
            "Epoch 16/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4390 - loss: 3.5107\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4431 - loss: 3.5442\n",
            "\n",
            "Epoch 17/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4686 - loss: 3.3573\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4731 - loss: 3.3893\n",
            "\n",
            "Epoch 18/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4964 - loss: 3.2110\n",
            "105/105 ━━━━━━━━━━━━━ 48s total - accuracy: 0.5011 - loss: 3.2416\n",
            "\n",
            "Epoch 19/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5222 - loss: 3.0724\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.5272 - loss: 3.1016\n",
            "\n",
            "Epoch 20/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5459 - loss: 2.9416\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.5511 - loss: 2.9696\n",
            "\n",
            "Epoch 21/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5676 - loss: 2.8188\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.5730 - loss: 2.8456\n",
            "\n",
            "Epoch 22/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.5875 - loss: 2.7038\n",
            "105/105 ━━━━━━━━━━━━━ 45s total - accuracy: 0.5931 - loss: 2.7296\n",
            "\n",
            "Epoch 23/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6058 - loss: 2.5962\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.6116 - loss: 2.6209\n",
            "\n",
            "Epoch 24/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6225 - loss: 2.4957\n",
            "105/105 ━━━━━━━━━━━━━ 46s total - accuracy: 0.6284 - loss: 2.5195\n",
            "\n",
            "Epoch 25/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6379 - loss: 2.4017\n",
            "105/105 ━━━━━━━━━━━━━ 47s total - accuracy: 0.6440 - loss: 2.4246\n",
            "\n",
            "Epoch 26/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6521 - loss: 2.3139\n",
            "105/105 ━━━━━━━━━━━━━ 48s total - accuracy: 0.6583 - loss: 2.3360\n",
            "\n",
            "Epoch 27/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6652 - loss: 2.2317\n",
            "105/105 ━━━━━━━━━━━━━ 48s total - accuracy: 0.6715 - loss: 2.2530\n",
            "\n",
            "Epoch 28/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6774 - loss: 2.1547\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.6838 - loss: 2.1752\n",
            "\n",
            "Epoch 29/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6887 - loss: 2.0825\n",
            "105/105 ━━━━━━━━━━━━━ 49s total - accuracy: 0.6952 - loss: 2.1023\n",
            "\n",
            "Epoch 30/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.6992 - loss: 2.0147\n",
            "105/105 ━━━━━━━━━━━━━ 50s total - accuracy: 0.7059 - loss: 2.0339\n",
            "\n",
            "Epoch 31/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7091 - loss: 1.9511\n",
            "105/105 ━━━━━━━━━━━━━ 50s total - accuracy: 0.7159 - loss: 1.9696\n",
            "\n",
            "Epoch 32/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7183 - loss: 1.8911\n",
            "105/105 ━━━━━━━━━━━━━ 51s total - accuracy: 0.7252 - loss: 1.9091\n",
            "\n",
            "Epoch 33/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7270 - loss: 1.8346\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.7339 - loss: 1.8521\n",
            "\n",
            "Epoch 34/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7351 - loss: 1.7813\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.7421 - loss: 1.7982\n",
            "\n",
            "Epoch 35/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7428 - loss: 1.7309\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.7499 - loss: 1.7474\n",
            "\n",
            "Epoch 36/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7501 - loss: 1.6832\n",
            "105/105 ━━━━━━━━━━━━━ 52s total - accuracy: 0.7572 - loss: 1.6992\n",
            "\n",
            "Epoch 37/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7569 - loss: 1.6380\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.7641 - loss: 1.6536\n",
            "\n",
            "Epoch 38/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7634 - loss: 1.5952\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.7707 - loss: 1.6104\n",
            "\n",
            "Epoch 39/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7695 - loss: 1.5545\n",
            "105/105 ━━━━━━━━━━━━━ 55s total - accuracy: 0.7769 - loss: 1.5693\n",
            "\n",
            "Epoch 40/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7754 - loss: 1.5158\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.7828 - loss: 1.5302\n",
            "\n",
            "Epoch 41/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7809 - loss: 1.4789\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.7884 - loss: 1.4930\n",
            "\n",
            "Epoch 42/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7862 - loss: 1.4438\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.7937 - loss: 1.4576\n",
            "\n",
            "Epoch 43/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7912 - loss: 1.4103\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.7988 - loss: 1.4238\n",
            "\n",
            "Epoch 44/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.7960 - loss: 1.3783\n",
            "105/105 ━━━━━━━━━━━━━ 55s total - accuracy: 0.8036 - loss: 1.3914\n",
            "\n",
            "Epoch 45/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8006 - loss: 1.3477\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.8082 - loss: 1.3606\n",
            "\n",
            "Epoch 46/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8050 - loss: 1.3184\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.8127 - loss: 1.3310\n",
            "\n",
            "Epoch 47/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8092 - loss: 1.2904\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.8169 - loss: 1.3027\n",
            "\n",
            "Epoch 48/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8132 - loss: 1.2635\n",
            "105/105 ━━━━━━━━━━━━━ 57s total - accuracy: 0.8209 - loss: 1.2755\n",
            "\n",
            "Epoch 49/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8171 - loss: 1.2377\n",
            "105/105 ━━━━━━━━━━━━━ 53s total - accuracy: 0.8248 - loss: 1.2495\n",
            "\n",
            "Epoch 50/50\n",
            "106/105 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.8208 - loss: 1.2129\n",
            "105/105 ━━━━━━━━━━━━━ 54s total - accuracy: 0.8286 - loss: 1.2245\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0526, 0.5255, 0.5255, 0.0642)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_150_300_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 250 # Adjust embedding dimension\n",
        "hidden_units = 450   # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 64      # Adjust batch size\n",
        "epochs = 50          # Increase number of epochs\n",
        "learning_rate = 0.00025  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.2),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NqC6qHJfg-qB",
        "outputId": "88e13dd4-60c6-417a-90be-1807f67fadac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m250\u001b[0m)             │         \u001b[38;5;34m830,750\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)                 │         \u001b[38;5;34m947,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,498,673\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">830,750</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">947,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,498,673</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,277,123\u001b[0m (12.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,123</span> (12.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,277,123\u001b[0m (12.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,123</span> (12.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1994 - loss: 7.9539\n",
            "52/52 ━━━━━━━━━━━━━ 23s total - accuracy: 0.2032 - loss: 8.1069\n",
            "\n",
            "Epoch 2/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1620 - loss: 7.0527\n",
            "52/52 ━━━━━━━━━━━━━ 22s total - accuracy: 0.1651 - loss: 7.1883\n",
            "\n",
            "Epoch 3/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1596 - loss: 6.5329\n",
            "52/52 ━━━━━━━━━━━━━ 23s total - accuracy: 0.1627 - loss: 6.6585\n",
            "\n",
            "Epoch 4/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1756 - loss: 6.2261\n",
            "52/52 ━━━━━━━━━━━━━ 24s total - accuracy: 0.1790 - loss: 6.3459\n",
            "\n",
            "Epoch 5/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1851 - loss: 6.0193\n",
            "52/52 ━━━━━━━━━━━━━ 24s total - accuracy: 0.1887 - loss: 6.1351\n",
            "\n",
            "Epoch 6/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1924 - loss: 5.8628\n",
            "52/52 ━━━━━━━━━━━━━ 25s total - accuracy: 0.1961 - loss: 5.9756\n",
            "\n",
            "Epoch 7/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1994 - loss: 5.7370\n",
            "52/52 ━━━━━━━━━━━━━ 25s total - accuracy: 0.2032 - loss: 5.8474\n",
            "\n",
            "Epoch 8/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2047 - loss: 5.6283\n",
            "52/52 ━━━━━━━━━━━━━ 25s total - accuracy: 0.2087 - loss: 5.7366\n",
            "\n",
            "Epoch 9/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2099 - loss: 5.5280\n",
            "52/52 ━━━━━━━━━━━━━ 26s total - accuracy: 0.2140 - loss: 5.6343\n",
            "\n",
            "Epoch 10/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2163 - loss: 5.4311\n",
            "52/52 ━━━━━━━━━━━━━ 26s total - accuracy: 0.2205 - loss: 5.5355\n",
            "\n",
            "Epoch 11/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2229 - loss: 5.3355\n",
            "52/52 ━━━━━━━━━━━━━ 27s total - accuracy: 0.2272 - loss: 5.4381\n",
            "\n",
            "Epoch 12/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2298 - loss: 5.2398\n",
            "52/52 ━━━━━━━━━━━━━ 27s total - accuracy: 0.2342 - loss: 5.3406\n",
            "\n",
            "Epoch 13/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2371 - loss: 5.1440\n",
            "52/52 ━━━━━━━━━━━━━ 28s total - accuracy: 0.2416 - loss: 5.2429\n",
            "\n",
            "Epoch 14/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2444 - loss: 5.0480\n",
            "52/52 ━━━━━━━━━━━━━ 28s total - accuracy: 0.2491 - loss: 5.1450\n",
            "\n",
            "Epoch 15/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2522 - loss: 4.9517\n",
            "52/52 ━━━━━━━━━━━━━ 29s total - accuracy: 0.2571 - loss: 5.0469\n",
            "\n",
            "Epoch 16/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2608 - loss: 4.8554\n",
            "52/52 ━━━━━━━━━━━━━ 30s total - accuracy: 0.2658 - loss: 4.9487\n",
            "\n",
            "Epoch 17/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2704 - loss: 4.7592\n",
            "52/52 ━━━━━━━━━━━━━ 31s total - accuracy: 0.2756 - loss: 4.8507\n",
            "\n",
            "Epoch 18/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2810 - loss: 4.6632\n",
            "52/52 ━━━━━━━━━━━━━ 32s total - accuracy: 0.2864 - loss: 4.7529\n",
            "\n",
            "Epoch 19/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.2924 - loss: 4.5675\n",
            "52/52 ━━━━━━━━━━━━━ 33s total - accuracy: 0.2980 - loss: 4.6554\n",
            "\n",
            "Epoch 20/50\n",
            "53/52 ━━━━━━━━━━━━━ -18s remaining - accuracy: 0.3045 - loss: 4.4722\n",
            "52/52 ━━━━━━━━━━━━━ 992s total - accuracy: 0.3104 - loss: 4.5582\n",
            "\n",
            "Epoch 21/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3173 - loss: 4.3774\n",
            "52/52 ━━━━━━━━━━━━━ 63s total - accuracy: 0.3234 - loss: 4.4616\n",
            "\n",
            "Epoch 22/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3307 - loss: 4.2832\n",
            "52/52 ━━━━━━━━━━━━━ 59s total - accuracy: 0.3370 - loss: 4.3656\n",
            "\n",
            "Epoch 23/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3449 - loss: 4.1899\n",
            "52/52 ━━━━━━━━━━━━━ 59s total - accuracy: 0.3515 - loss: 4.2704\n",
            "\n",
            "Epoch 24/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3601 - loss: 4.0972\n",
            "52/52 ━━━━━━━━━━━━━ 56s total - accuracy: 0.3670 - loss: 4.1760\n",
            "\n",
            "Epoch 25/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3762 - loss: 4.0056\n",
            "52/52 ━━━━━━━━━━━━━ 56s total - accuracy: 0.3834 - loss: 4.0826\n",
            "\n",
            "Epoch 26/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.3931 - loss: 3.9151\n",
            "52/52 ━━━━━━━━━━━━━ 54s total - accuracy: 0.4006 - loss: 3.9904\n",
            "\n",
            "Epoch 27/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.4104 - loss: 3.8261\n",
            "52/52 ━━━━━━━━━━━━━ 53s total - accuracy: 0.4183 - loss: 3.8996\n",
            "\n",
            "Epoch 28/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4277 - loss: 3.7389\n",
            "52/52 ━━━━━━━━━━━━━ 48s total - accuracy: 0.4359 - loss: 3.8108\n",
            "\n",
            "Epoch 29/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.4448 - loss: 3.6533\n",
            "52/52 ━━━━━━━━━━━━━ 47s total - accuracy: 0.4533 - loss: 3.7236\n",
            "\n",
            "Epoch 30/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.4617 - loss: 3.5690\n",
            "52/52 ━━━━━━━━━━━━━ 55s total - accuracy: 0.4706 - loss: 3.6376\n",
            "\n",
            "Epoch 31/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.4782 - loss: 3.4860\n",
            "52/52 ━━━━━━━━━━━━━ 54s total - accuracy: 0.4874 - loss: 3.5530\n",
            "\n",
            "Epoch 32/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.4942 - loss: 3.4046\n",
            "52/52 ━━━━━━━━━━━━━ 57s total - accuracy: 0.5037 - loss: 3.4701\n",
            "\n",
            "Epoch 33/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5094 - loss: 3.3252\n",
            "52/52 ━━━━━━━━━━━━━ 69s total - accuracy: 0.5192 - loss: 3.3892\n",
            "\n",
            "Epoch 34/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5239 - loss: 3.2478\n",
            "52/52 ━━━━━━━━━━━━━ 69s total - accuracy: 0.5340 - loss: 3.3102\n",
            "\n",
            "Epoch 35/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5376 - loss: 3.1724\n",
            "52/52 ━━━━━━━━━━━━━ 71s total - accuracy: 0.5479 - loss: 3.2334\n",
            "\n",
            "Epoch 36/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5506 - loss: 3.0993\n",
            "52/52 ━━━━━━━━━━━━━ 74s total - accuracy: 0.5612 - loss: 3.1589\n",
            "\n",
            "Epoch 37/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5629 - loss: 3.0283\n",
            "52/52 ━━━━━━━━━━━━━ 76s total - accuracy: 0.5737 - loss: 3.0866\n",
            "\n",
            "Epoch 38/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5745 - loss: 2.9596\n",
            "52/52 ━━━━━━━━━━━━━ 77s total - accuracy: 0.5856 - loss: 3.0165\n",
            "\n",
            "Epoch 39/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5856 - loss: 2.8932\n",
            "52/52 ━━━━━━━━━━━━━ 82s total - accuracy: 0.5968 - loss: 2.9488\n",
            "\n",
            "Epoch 40/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.5961 - loss: 2.8290\n",
            "52/52 ━━━━━━━━━━━━━ 88s total - accuracy: 0.6075 - loss: 2.8834\n",
            "\n",
            "Epoch 41/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6060 - loss: 2.7670\n",
            "52/52 ━━━━━━━━━━━━━ 90s total - accuracy: 0.6177 - loss: 2.8202\n",
            "\n",
            "Epoch 42/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6155 - loss: 2.7072\n",
            "52/52 ━━━━━━━━━━━━━ 90s total - accuracy: 0.6274 - loss: 2.7593\n",
            "\n",
            "Epoch 43/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6246 - loss: 2.6496\n",
            "52/52 ━━━━━━━━━━━━━ 96s total - accuracy: 0.6366 - loss: 2.7006\n",
            "\n",
            "Epoch 44/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6332 - loss: 2.5940\n",
            "52/52 ━━━━━━━━━━━━━ 98s total - accuracy: 0.6454 - loss: 2.6439\n",
            "\n",
            "Epoch 45/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6414 - loss: 2.5404\n",
            "52/52 ━━━━━━━━━━━━━ 103s total - accuracy: 0.6538 - loss: 2.5893\n",
            "\n",
            "Epoch 46/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6493 - loss: 2.4888\n",
            "52/52 ━━━━━━━━━━━━━ 105s total - accuracy: 0.6618 - loss: 2.5367\n",
            "\n",
            "Epoch 47/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.6569 - loss: 2.4389\n",
            "52/52 ━━━━━━━━━━━━━ 109s total - accuracy: 0.6695 - loss: 2.4858\n",
            "\n",
            "Epoch 48/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.6641 - loss: 2.3908\n",
            "52/52 ━━━━━━━━━━━━━ 111s total - accuracy: 0.6769 - loss: 2.4368\n",
            "\n",
            "Epoch 49/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.6710 - loss: 2.3444\n",
            "52/52 ━━━━━━━━━━━━━ 106s total - accuracy: 0.6839 - loss: 2.3895\n",
            "\n",
            "Epoch 50/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.6777 - loss: 2.2996\n",
            "52/52 ━━━━━━━━━━━━━ 100s total - accuracy: 0.6907 - loss: 2.3438\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0505, 0.5053, 0.5053, 0.0635)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_250_450_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# CPU Optimization Settings\n",
        "tf.config.threading.set_intra_op_parallelism_threads(16)\n",
        "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Hyperparameters (Update for Each Experiment)\n",
        "embedding_dim = 250 # Adjust embedding dimension\n",
        "hidden_units = 450   # Adjust GRU units\n",
        "sequence_length = 20 # Sequence length\n",
        "batch_size = 64      # Adjust batch size\n",
        "epochs = 50          # Increase number of epochs\n",
        "learning_rate = 0.0001  # Learning rate\n",
        "\n",
        "# Load Preprocessed Data\n",
        "X_train = np.load(\"X_train.npy\")\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_train = np.load(\"y_train.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "unique_items = np.load(\"unique_items.npy\")\n",
        "\n",
        "# Prepare Data with tf.data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Build and Compile Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(unique_items), output_dim=embedding_dim, input_length=sequence_length),\n",
        "    GRU(units=hidden_units, return_sequences=False, dropout=0.3),\n",
        "    Dense(units=len(unique_items), activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, sequence_length))\n",
        "model.summary()\n",
        "\n",
        "# Training with Step and Countdown Display\n",
        "steps_per_epoch = max(1, len(X_train) // batch_size)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    start_time = time.time()\n",
        "    training_loss, training_accuracy = 0, 0\n",
        "\n",
        "    for step, (x_batch, y_batch) in enumerate(train_dataset, start=1):\n",
        "        metrics = model.train_on_batch(x_batch, y_batch)\n",
        "        training_loss += metrics[0]\n",
        "        training_accuracy += metrics[1]\n",
        "\n",
        "        # Estimate remaining time\n",
        "        elapsed_time = time.time() - start_time\n",
        "        steps_remaining = steps_per_epoch - step\n",
        "        time_per_step = elapsed_time / max(1, step)\n",
        "        estimated_time_remaining = steps_remaining * time_per_step\n",
        "\n",
        "        # Dynamic updates\n",
        "        print(\n",
        "            f\"\\r{step}/{steps_per_epoch} ━━━━━━━━━━━━━ {int(estimated_time_remaining)}s remaining - \"\n",
        "            f\"accuracy: {training_accuracy / step:.4f} - loss: {training_loss / step:.4f}\", end=\"\"\n",
        "        )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(\n",
        "        f\"\\n{steps_per_epoch}/{steps_per_epoch} ━━━━━━━━━━━━━ \"\n",
        "        f\"{int(epoch_time)}s total - accuracy: {training_accuracy / steps_per_epoch:.4f} - \"\n",
        "        f\"loss: {training_loss / steps_per_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "# Evaluate the Model\n",
        "def evaluate_model(model, test_data, k=10):\n",
        "    total_precision, total_recall, total_hits, total_mrr = 0, 0, 0, 0\n",
        "    total_users = 0\n",
        "\n",
        "    for x, y_true in test_data:\n",
        "        y_pred = model.predict(x, verbose=0)\n",
        "        top_k_indices = np.argsort(y_pred, axis=1)[:, -k:]\n",
        "\n",
        "        for idx, target in enumerate(y_true):\n",
        "            predictions = top_k_indices[idx]\n",
        "            target = int(target.numpy())\n",
        "            if target in predictions:\n",
        "                rank = np.where(predictions == target)[0][0] + 1\n",
        "                total_hits += 1\n",
        "                total_mrr += 1 / rank\n",
        "\n",
        "            precision_k = len(set(predictions) & {target}) / k\n",
        "            recall_k = len(set(predictions) & {target}) / 1\n",
        "            total_precision += precision_k\n",
        "            total_recall += recall_k\n",
        "\n",
        "        total_users += len(y_true)\n",
        "\n",
        "    precision = total_precision / total_users\n",
        "    recall = total_recall / total_users\n",
        "    hit_rate = total_hits / total_users\n",
        "    mrr = total_mrr / total_users\n",
        "\n",
        "    return precision, recall, hit_rate, mrr\n",
        "\n",
        "# Evaluate\n",
        "results = evaluate_model(model, test_dataset, k=10)\n",
        "print(\"\\nFinal Results (Precision@10, Recall@10, Hit Rate, MRR):\")\n",
        "print(f\"({results[0]:.4f}, {results[1]:.4f}, {results[2]:.4f}, {results[3]:.4f})\")\n",
        "\n",
        "# Save Results to CSV\n",
        "def save_results(results, base_path, file_name):\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"Precision@10\": results[0],\n",
        "        \"Recall@10\": results[1],\n",
        "        \"Hit Rate\": results[2],\n",
        "        \"MRR\": results[3],\n",
        "    }])\n",
        "    file_path = os.path.join(base_path, file_name)\n",
        "    result_df.to_csv(file_path, index=False)\n",
        "\n",
        "base_path = r\"C:\\Users\\user\\Desktop\\CW4\\online+retail\"\n",
        "save_results(results, base_path, f\"evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv\")\n",
        "print(f\"Results saved to {os.path.join(base_path, f'evaluation_results_experiment_{embedding_dim}_{hidden_units}_{epochs}.csv')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5JdAbV8hIcL",
        "outputId": "0ac213fd-1ef4-4b5b-ba1a-3115ab0ae7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m250\u001b[0m)             │         \u001b[38;5;34m830,750\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)                 │         \u001b[38;5;34m947,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3323\u001b[0m)                │       \u001b[38;5;34m1,498,673\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">830,750</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">947,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3323</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,498,673</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,277,123\u001b[0m (12.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,123</span> (12.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,277,123\u001b[0m (12.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,123</span> (12.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.1210 - loss: 8.0974\n",
            "52/52 ━━━━━━━━━━━━━ 120s total - accuracy: 0.1233 - loss: 8.2532\n",
            "\n",
            "Epoch 2/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.1420 - loss: 7.7949\n",
            "52/52 ━━━━━━━━━━━━━ 119s total - accuracy: 0.1447 - loss: 7.9448\n",
            "\n",
            "Epoch 3/50\n",
            "47/52 ━━━━━━━━━━━━━ 11s remaining - accuracy: 0.1447 - loss: 7.1623"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000136E5664490>>\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/52 ━━━━━━━━━━━━━ -8s remaining - accuracy: 0.1450 - loss: 7.1409\n",
            "52/52 ━━━━━━━━━━━━━ 450s total - accuracy: 0.1478 - loss: 7.2783\n",
            "\n",
            "Epoch 4/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1462 - loss: 6.7719\n",
            "52/52 ━━━━━━━━━━━━━ 55s total - accuracy: 0.1490 - loss: 6.9021\n",
            "\n",
            "Epoch 5/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1473 - loss: 6.5394\n",
            "52/52 ━━━━━━━━━━━━━ 60s total - accuracy: 0.1502 - loss: 6.6652\n",
            "\n",
            "Epoch 6/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1574 - loss: 6.3688\n",
            "52/52 ━━━━━━━━━━━━━ 55s total - accuracy: 0.1604 - loss: 6.4913\n",
            "\n",
            "Epoch 7/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1667 - loss: 6.2346\n",
            "52/52 ━━━━━━━━━━━━━ 49s total - accuracy: 0.1699 - loss: 6.3545\n",
            "\n",
            "Epoch 8/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1736 - loss: 6.1258\n",
            "52/52 ━━━━━━━━━━━━━ 48s total - accuracy: 0.1769 - loss: 6.2436\n",
            "\n",
            "Epoch 9/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1789 - loss: 6.0347\n",
            "52/52 ━━━━━━━━━━━━━ 50s total - accuracy: 0.1823 - loss: 6.1508\n",
            "\n",
            "Epoch 10/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1838 - loss: 5.9563\n",
            "52/52 ━━━━━━━━━━━━━ 48s total - accuracy: 0.1873 - loss: 6.0708\n",
            "\n",
            "Epoch 11/50\n",
            "53/52 ━━━━━━━━━━━━━ 0s remaining - accuracy: 0.1885 - loss: 5.8873\n",
            "52/52 ━━━━━━━━━━━━━ 52s total - accuracy: 0.1921 - loss: 6.0005\n",
            "\n",
            "Epoch 12/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1927 - loss: 5.8259\n",
            "52/52 ━━━━━━━━━━━━━ 54s total - accuracy: 0.1964 - loss: 5.9379\n",
            "\n",
            "Epoch 13/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1963 - loss: 5.7709\n",
            "52/52 ━━━━━━━━━━━━━ 54s total - accuracy: 0.2001 - loss: 5.8819\n",
            "\n",
            "Epoch 14/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.1994 - loss: 5.7211\n",
            "52/52 ━━━━━━━━━━━━━ 58s total - accuracy: 0.2033 - loss: 5.8312\n",
            "\n",
            "Epoch 15/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2021 - loss: 5.6756\n",
            "52/52 ━━━━━━━━━━━━━ 58s total - accuracy: 0.2060 - loss: 5.7847\n",
            "\n",
            "Epoch 16/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2046 - loss: 5.6332\n",
            "52/52 ━━━━━━━━━━━━━ 60s total - accuracy: 0.2085 - loss: 5.7415\n",
            "\n",
            "Epoch 17/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2070 - loss: 5.5935\n",
            "52/52 ━━━━━━━━━━━━━ 63s total - accuracy: 0.2110 - loss: 5.7010\n",
            "\n",
            "Epoch 18/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2092 - loss: 5.5558\n",
            "52/52 ━━━━━━━━━━━━━ 65s total - accuracy: 0.2132 - loss: 5.6626\n",
            "\n",
            "Epoch 19/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2113 - loss: 5.5197\n",
            "52/52 ━━━━━━━━━━━━━ 70s total - accuracy: 0.2153 - loss: 5.6258\n",
            "\n",
            "Epoch 20/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2135 - loss: 5.4848\n",
            "52/52 ━━━━━━━━━━━━━ 74s total - accuracy: 0.2176 - loss: 5.5903\n",
            "\n",
            "Epoch 21/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2155 - loss: 5.4509\n",
            "52/52 ━━━━━━━━━━━━━ 77s total - accuracy: 0.2197 - loss: 5.5557\n",
            "\n",
            "Epoch 22/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2175 - loss: 5.4177\n",
            "52/52 ━━━━━━━━━━━━━ 81s total - accuracy: 0.2217 - loss: 5.5219\n",
            "\n",
            "Epoch 23/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2193 - loss: 5.3851\n",
            "52/52 ━━━━━━━━━━━━━ 86s total - accuracy: 0.2235 - loss: 5.4887\n",
            "\n",
            "Epoch 24/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2209 - loss: 5.3529\n",
            "52/52 ━━━━━━━━━━━━━ 89s total - accuracy: 0.2252 - loss: 5.4559\n",
            "\n",
            "Epoch 25/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2225 - loss: 5.3211\n",
            "52/52 ━━━━━━━━━━━━━ 93s total - accuracy: 0.2268 - loss: 5.4234\n",
            "\n",
            "Epoch 26/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2240 - loss: 5.2895\n",
            "52/52 ━━━━━━━━━━━━━ 98s total - accuracy: 0.2284 - loss: 5.3912\n",
            "\n",
            "Epoch 27/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2256 - loss: 5.2580\n",
            "52/52 ━━━━━━━━━━━━━ 101s total - accuracy: 0.2300 - loss: 5.3591\n",
            "\n",
            "Epoch 28/50\n",
            "53/52 ━━━━━━━━━━━━━ -1s remaining - accuracy: 0.2274 - loss: 5.2265\n",
            "52/52 ━━━━━━━━━━━━━ 105s total - accuracy: 0.2317 - loss: 5.3270\n",
            "\n",
            "Epoch 29/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2293 - loss: 5.1951\n",
            "52/52 ━━━━━━━━━━━━━ 111s total - accuracy: 0.2337 - loss: 5.2950\n",
            "\n",
            "Epoch 30/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2314 - loss: 5.1636\n",
            "52/52 ━━━━━━━━━━━━━ 113s total - accuracy: 0.2359 - loss: 5.2629\n",
            "\n",
            "Epoch 31/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2337 - loss: 5.1321\n",
            "52/52 ━━━━━━━━━━━━━ 115s total - accuracy: 0.2382 - loss: 5.2308\n",
            "\n",
            "Epoch 32/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2362 - loss: 5.1005\n",
            "52/52 ━━━━━━━━━━━━━ 119s total - accuracy: 0.2407 - loss: 5.1986\n",
            "\n",
            "Epoch 33/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2386 - loss: 5.0688\n",
            "52/52 ━━━━━━━━━━━━━ 124s total - accuracy: 0.2432 - loss: 5.1663\n",
            "\n",
            "Epoch 34/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2411 - loss: 5.0370\n",
            "52/52 ━━━━━━━━━━━━━ 125s total - accuracy: 0.2457 - loss: 5.1339\n",
            "\n",
            "Epoch 35/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2437 - loss: 5.0050\n",
            "52/52 ━━━━━━━━━━━━━ 128s total - accuracy: 0.2484 - loss: 5.1012\n",
            "\n",
            "Epoch 36/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2465 - loss: 4.9728\n",
            "52/52 ━━━━━━━━━━━━━ 132s total - accuracy: 0.2512 - loss: 5.0685\n",
            "\n",
            "Epoch 37/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2493 - loss: 4.9406\n",
            "52/52 ━━━━━━━━━━━━━ 137s total - accuracy: 0.2541 - loss: 5.0357\n",
            "\n",
            "Epoch 38/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2521 - loss: 4.9082\n",
            "52/52 ━━━━━━━━━━━━━ 139s total - accuracy: 0.2569 - loss: 5.0026\n",
            "\n",
            "Epoch 39/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2551 - loss: 4.8756\n",
            "52/52 ━━━━━━━━━━━━━ 143s total - accuracy: 0.2600 - loss: 4.9694\n",
            "\n",
            "Epoch 40/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2582 - loss: 4.8429\n",
            "52/52 ━━━━━━━━━━━━━ 144s total - accuracy: 0.2631 - loss: 4.9360\n",
            "\n",
            "Epoch 41/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2613 - loss: 4.8100\n",
            "52/52 ━━━━━━━━━━━━━ 146s total - accuracy: 0.2663 - loss: 4.9025\n",
            "\n",
            "Epoch 42/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2647 - loss: 4.7769\n",
            "52/52 ━━━━━━━━━━━━━ 149s total - accuracy: 0.2698 - loss: 4.8688\n",
            "\n",
            "Epoch 43/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2682 - loss: 4.7437\n",
            "52/52 ━━━━━━━━━━━━━ 142s total - accuracy: 0.2733 - loss: 4.8350\n",
            "\n",
            "Epoch 44/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2718 - loss: 4.7105\n",
            "52/52 ━━━━━━━━━━━━━ 141s total - accuracy: 0.2770 - loss: 4.8011\n",
            "\n",
            "Epoch 45/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2755 - loss: 4.6771\n",
            "52/52 ━━━━━━━━━━━━━ 144s total - accuracy: 0.2808 - loss: 4.7671\n",
            "\n",
            "Epoch 46/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2792 - loss: 4.6436\n",
            "52/52 ━━━━━━━━━━━━━ 145s total - accuracy: 0.2846 - loss: 4.7329\n",
            "\n",
            "Epoch 47/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2831 - loss: 4.6100\n",
            "52/52 ━━━━━━━━━━━━━ 147s total - accuracy: 0.2885 - loss: 4.6986\n",
            "\n",
            "Epoch 48/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2871 - loss: 4.5763\n",
            "52/52 ━━━━━━━━━━━━━ 148s total - accuracy: 0.2926 - loss: 4.6644\n",
            "\n",
            "Epoch 49/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2911 - loss: 4.5426\n",
            "52/52 ━━━━━━━━━━━━━ 149s total - accuracy: 0.2967 - loss: 4.6300\n",
            "\n",
            "Epoch 50/50\n",
            "53/52 ━━━━━━━━━━━━━ -2s remaining - accuracy: 0.2952 - loss: 4.5089\n",
            "52/52 ━━━━━━━━━━━━━ 151s total - accuracy: 0.3009 - loss: 4.5956\n",
            "\n",
            "Final Results (Precision@10, Recall@10, Hit Rate, MRR):\n",
            "(0.0359, 0.3594, 0.3594, 0.0452)\n",
            "Results saved to C:\\Users\\user\\Desktop\\CW4\\online+retail\\evaluation_results_experiment_250_450_50.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zcBWe4e45cc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}